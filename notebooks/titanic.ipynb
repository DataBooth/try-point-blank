{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import pointblank as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITANIC_URL = 'https://hbiostat.org/data/repo/titanic3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_db(db_path='titanic.duckdb', url=TITANIC_URL, force_create=False):\n",
    "    if not Path(db_path).exists() or force_create:\n",
    "        # Connect to DuckDB and create a persistent database\n",
    "        con = duckdb.connect(database=db_path, read_only=False)\n",
    "\n",
    "        # Read the CSV files directly into DuckDB\n",
    "        con.execute(f\"CREATE TABLE IF NOT EXISTS titanic AS SELECT * FROM read_csv('{url}')\")\n",
    "        # Create a new table with a unique identifier\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE titanic_with_id AS \n",
    "            SELECT *, ROW_NUMBER() OVER () AS id \n",
    "            FROM titanic\n",
    "        \"\"\")\n",
    "        # Drop the original table and rename the new table\n",
    "        con.execute(\"DROP TABLE titanic\")\n",
    "        con.execute(\"ALTER TABLE titanic_with_id RENAME TO titanic\")\n",
    "    else:\n",
    "        # Connect to the existing database\n",
    "        con = duckdb.connect(database=db_path, read_only=False)\n",
    "    \n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = get_or_create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT COUNT(*) FROM titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM titanic LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_samples(con, n_sample):\n",
    "    # Get the total number of rows in the titanic table\n",
    "    total_rows = con.sql(\"SELECT COUNT(*) FROM titanic\").fetchone()[0]\n",
    "    \n",
    "    # Calculate the number of rows per sample\n",
    "    rows_per_sample = math.ceil(total_rows / n_sample)\n",
    "    \n",
    "    # Get all rows and shuffle them\n",
    "    all_rows = con.sql(\"SELECT * FROM titanic\").fetchdf()\n",
    "    shuffled_rows = all_rows.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(n_sample):\n",
    "        offset = i * rows_per_sample\n",
    "        sample = shuffled_rows.iloc[offset:offset + rows_per_sample]\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5  # Define the number of samples you want\n",
    "sample = create_random_samples(con, n_sample)\n",
    "\n",
    "# Display the first sample to verify\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the original dataframe from the database\n",
    "original_df = con.sql(\"SELECT * FROM titanic\").fetchdf()\n",
    "\n",
    "# Concatenate all samples into a single dataframe\n",
    "concatenated_samples = pd.concat(sample).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "# Check if the dataframes are identical\n",
    "are_identical = original_df.equals(concatenated_samples)\n",
    "\n",
    "print(f\"Are the original dataframe and concatenated samples identical? {'Yes' if are_identical else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb.preview(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = (\n",
    "    pb.Validate(data=original_df, label=\"Example Validation\")\n",
    "    .col_exists(\"name\")\n",
    "    .col_exists(\"age\")\n",
    "    .col_vals_not_null(\"survived\")\n",
    "    .col_vals_not_null(\"pclass\")\n",
    "    .col_vals_not_null(\"sex\")\n",
    "    .col_vals_not_null(\"ticket\")\n",
    "    .col_vals_not_null(\"fare\")\n",
    "    .col_vals_not_null(\"embarked\")\n",
    "    .col_vals_between(\"age\", 0, 70, na_pass=True)\n",
    "    .col_vals_between(\"fare\", 0, 500)\n",
    "    .col_vals_in_set(\"pclass\", {1, 2, 3})\n",
    "    .col_vals_in_set(\"embarked\", {\"C\", \"Q\", \"S\"})\n",
    "    .col_vals_in_set(\"survived\", {0, 1})\n",
    "    .col_vals_in_set(\"sex\", {\"male\", \"female\"})\n",
    "    .interrogate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
