{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating `Pointblank`\n",
    "\n",
    "https://posit-dev.github.io/pointblank/\n",
    "\n",
    "The following types of tables are supported:\n",
    "\n",
    "- Polars DataFrame\n",
    "- Pandas DataFrame\n",
    "- DuckDB table\n",
    "- MySQL table\n",
    "- PostgreSQL table\n",
    "- SQLite table\n",
    "- Parquet\n",
    "\n",
    "It uses `Narwhals` to work with `Polars` and `Pandas` DataFrames and also integrates with `Ibis` to enable the use of `DuckDB`, `MySQL`, `PostgreSQL`, `SQLite`, `Parquet`, and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import pointblank as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITANIC_URL = 'https://hbiostat.org/data/repo/titanic3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_db(db_path='titanic.duckdb', url=TITANIC_URL, force_create=False):\n",
    "    if not Path(db_path).exists() or force_create:\n",
    "        # Connect to DuckDB and create a persistent database\n",
    "        con = duckdb.connect(database=db_path, read_only=False)\n",
    "\n",
    "        # Read the CSV files directly into DuckDB\n",
    "        con.execute(f\"CREATE TABLE IF NOT EXISTS titanic AS SELECT * FROM read_csv('{url}')\")\n",
    "        # Create a new table with a unique identifier\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE titanic_with_id AS \n",
    "            SELECT *, ROW_NUMBER() OVER () AS id \n",
    "            FROM titanic\n",
    "        \"\"\")\n",
    "        # Drop the original table and rename the new table\n",
    "        con.execute(\"DROP TABLE titanic\")\n",
    "        con.execute(\"ALTER TABLE titanic_with_id RENAME TO titanic\")\n",
    "    else:\n",
    "        # Connect to the existing database\n",
    "        con = duckdb.connect(database=db_path, read_only=False)\n",
    "    \n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = get_or_create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT COUNT(*) FROM titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM titanic LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_samples(con, n_sample):\n",
    "    # Get the total number of rows in the titanic table\n",
    "    total_rows = con.sql(\"SELECT COUNT(*) FROM titanic\").fetchone()[0]\n",
    "    \n",
    "    # Calculate the number of rows per sample\n",
    "    rows_per_sample = math.ceil(total_rows / n_sample)\n",
    "    \n",
    "    # Get all rows and shuffle them\n",
    "    all_rows = con.sql(\"SELECT * FROM titanic\").fetchdf()\n",
    "    shuffled_rows = all_rows.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(n_sample):\n",
    "        offset = i * rows_per_sample\n",
    "        sample = shuffled_rows.iloc[offset:offset + rows_per_sample]\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5  # Define the number of samples you want\n",
    "sample = create_random_samples(con, n_sample)\n",
    "\n",
    "# Display the first sample to verify\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the original dataframe from the database\n",
    "original_df = con.sql(\"SELECT * FROM titanic\").fetchdf()\n",
    "\n",
    "# Concatenate all samples into a single dataframe\n",
    "concatenated_samples = pd.concat(sample).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "# Check if the dataframes are identical\n",
    "are_identical = original_df.equals(concatenated_samples)\n",
    "\n",
    "print(f\"Are the original dataframe and concatenated samples identical? {'Yes' if are_identical else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb.preview(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_titanic_data_sample(sample_df):\n",
    "    \n",
    "    validation = (\n",
    "        pb.Validate(data=sample_df, label=\"Example Validation\")\n",
    "        .col_vals_not_null(\"survived\")\n",
    "        .col_vals_not_null(\"pclass\")\n",
    "        .col_vals_not_null(\"sex\")\n",
    "        .col_vals_not_null(\"age\")\n",
    "        .col_vals_not_null(\"ticket\")\n",
    "        .col_vals_not_null(\"fare\")\n",
    "        .col_vals_not_null(\"embarked\")\n",
    "        .col_vals_between(\"age\", 0, 70, na_pass=True)\n",
    "        .col_vals_between(\"fare\", 0, 500)\n",
    "        .col_vals_in_set(\"pclass\", {1, 2, 3})\n",
    "        .col_vals_in_set(\"embarked\", {\"C\", \"Q\", \"S\"})\n",
    "        .col_vals_in_set(\"survived\", {0, 1})\n",
    "        .col_vals_in_set(\"sex\", {\"male\", \"female\"})\n",
    "        .interrogate()\n",
    "    )\n",
    "\n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_titanic_data_sample(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use the first sample to \"define\" the thresholds and then process the remaining samples with thresholds and actions.\n",
    "\n",
    "https://posit-dev.github.io/pointblank/user-guide/thresholds.html\n",
    "\n",
    "https://posit-dev.github.io/pointblank/user-guide/actions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(sample):\n",
    "    validation = validate_titanic_data_sample(s)\n",
    "    display(f\"Sample {i+1} - size: {len(s)} rows\")\n",
    "    display(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4, 5, 6]:\n",
    "    display(validation.get_data_extracts(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
